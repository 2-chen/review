审稿这篇论文，审稿意见主要包括summary、strength、weakness. overall(reject, weak reject, weak accept, accept)。意见尽量详细，像负责人的审稿人对待你们的论文一样评审。

[**LLM-OAP: AN LLM-BASED DATA AUGMENTATION  FRAMEWORK FOR ENHANCING ORDER ACCEPTANCE  PREDICTION IN MOBILITY-ON-DEMAND SYSTEMS**](https://openreview.net/pdf?id=17wW0MWqjl)

**summary**

本文介绍了 LLM-OAP，这是一个基于 LLM 的数据增强框架，旨在通过使用 LLM 生成的高质量合成样本来增强小规模行为数据集，从而增强 Mobility-on-Demand (MoD) 系统中的订单接受预测性能。该方法通过特征感知分组将司机划分为不同人物画像，合成新的订单数据，再生成模拟行为决策标签，并应用基于置信度和不确定性的过滤方案来管理增强数据。在完整信息和有限信息下对真实世界陈述偏好 （stated-preference, SP） 调查数据集的评估表明，LLM-OAP 在最先进的机器学习模型上持续提高性能，优于各种经典和基于 LLM 的增强基线。提供了广泛的消融和实证分析。

**strength**

* 论文研究的是真实有价值的商业问题，抓住 MoD 行为预测的关键难点，数据少、分布空洞与建模非线性
* 该论文通过提出一个新颖的框架，利用 LLM 进行结构化、语义连贯的数据增强，解决了 MoD 系统行为建模中数据稀缺、主观性和陈述偏好调查的外部有效性有限等问题。
* 该框架的设计结合了特征感知角色分组、显式行为总结、合成订单生成和决策标签模拟，有效捕捉不同司机群体的决策偏好差异，避免单一模型拟合所有异构行为的弊端。具体流程在图 1 中有体现，描述了每个步骤并证明了设计选择的合理性。
* 为合成样本加入置信度/不确定性过滤机制有效避免了有偏见或嘈杂数据。图 3 中置信度和不确定性分布的分析体现了该筛选机制的影响，表明其可以有效降噪。
* 实验评估细致而全面。表 1 和表 3 提供了广泛的定量基准，表明 LLM-OAP 在准确性和概率质量指标（ACC、AUC、AUCPR、ECE、BS、NLL）方面优于 GAN、扩散模型和最近基于 LLM 的方法，无论是在完整信息制度还是有限信息制度下，对于该框架的鲁棒性有一定支撑。
* 图表制作较好，如图1直观地展示了整个框架的流程。消融研究（表 2、表 4）和策展比例分析（图 2）突出了每个框架组件的贡献。图 2 的雷达图对模型性能作为增强和管理策略函数进行了很好的可视化。
* 可复现性较好，论文写作整体清楚，方法流程、特征工程、实验设定清晰。提示设计（图 4）以可复现的方式进行了详细说明，可以作为未来行为数据合成相关工作的模板。
* 这项工作很好地结合了现有工作，参考了经典的 MoD 建模、传统增强和最近基于 LLM 的方法。



* 数据增强：
  * LLM用于结构化表格数据的生成，在行为建模领域是新颖的方向，设计了一套包含人物画像、行为总结、一致性检查和数据筛选的完整、精巧的流程
  * 分阶段prompt设计将复杂任务分解，保证生成数据的逻辑一致性和行为对齐【*分阶段prompt是什么，和LLM生成结构化表格数据有什么区别？*】
* 多样基线：与多种先进生成模型进行了比较，包括GAN、Diffusion以及其他LLM方法【*怎么和这种模型比？也拿这些模型来生成数据？那主体是什么？LLM？那其他LLM方法是什么？*】
* 不同LLM：测试了不同LLM的效果，如Deepseek-V3,R1,QWEN3-plus，表明该框架对LLM模型选择不敏感，通用性好
* 性能：取得一定突破

**weakness**

* 经验泛化性限制：评估仅针对 Ashkrof 等人（2022 年）收集的来自美国和荷兰的 SP 数据集进行，使用的是模拟行为数据而不是实际行为数据。虽然 SP 数据很常见，但它存在外部有效性问题，并且该框架在大规模真实 MoD 上的有效性未经检验，难以体现提高了泛化性和现实有效性。
* 潜在的 SP 数据过度拟合特质：策展过滤器依赖于仅在原始（通常是小的）SP 训练集上训练的 XGBoost 模型。这可能会在过滤过程中编码和延续数据集偏差或伪影。对于这种机制是否真正过滤行为保真度，而不仅仅是过滤与原始 SP 分布在统计上相似（但不一定更现实）的合成样本，没有足够的分析（经验或理论）。【？】
* 模式崩溃和多样性的处理不完整：虽然该框架试图通过角色分组和管理来解决多样性问题，但对生成数据中实质性多样性的定量分析有限。通过对模型置信度和不确定性进行阈值设置，数据筛选过程中可能会无意中促进安全模式或典型模式的过度呈现，从而损害司机行为的多样性，特别是在少数群体或罕见群体中。多样性的测量没有在任何表格或图形中体现。
* 基线范围：尽管基线很广，但本文忽略了 LLM 驱动的移动行为模拟、小型交通数据集的数据增强和基于 LLM 的代理建模等直接相关领域的一些关键工作。例如，Liu等人（2024）关于在 MoD 中使用机器学习进行驾驶员行为预测; Chen et al. （2023） 关于小型行为数据集的数据增强; Zhang et al. （2025） 关于整合 LLM 进行交通预测; Wang 等人（2022 年）关于用于驱动因素决策建模的机器学习; Li et al. （2024） 关于交通分析的合成数据——在基准和讨论中都直接相关且缺失。
* 特征选择和分组的详细信息：第 3.2 节解释了角色分组阶段，从前 10 个特征中随机选择（附录 A.2/表 5），但这种随机方法的说服力很弱：为什么不确定性地使用前 3 个或更系统的聚类方法？没有分组设计的敏感性分析，也没有评估组大小或特征选择如何影响多样性、现实性或模型性能。
* LLM 决策模拟的理论分析：第 3.2 节描述了 LLM 提供人物画像和模拟决策的过程，但该机制被视为黑匣子。除了 XGBoost 对合成数据进行筛选和提纯外，没有依据保证 LLM 生成的决策具有任何行为有效性，也没有任何定量的一致性检验。这在理解 LLM 生成的行为数据的潜在偏差方面留下了理论空白。基于方程的讨论仅限于排列重要性和过滤，而不是生成。
* 不考虑 LLM 幻觉或对抗鲁棒性：普遍认为 LLM 有生成逻辑不一致、重复甚至有害记录的风险（第 3 页），但论文仅为缓解提供个别案例支持。没有对生成的合成数据集进行明确的对抗性压力测试、人工审查或健全性检查。
* 可复现性细节：虽然需要代码才能实现完全可重复性，但某些细节（例如所有组的实际 LLM 提示）、过滤的超参数设置以及数据量和多样性的过滤前与过滤后统计数据，对于该工作的复现来说是不足的。
* 数据集规模和覆盖范围：相对于现实规模的数据量，该论文总数据大小非常小。表 8 列举了大量分类和连续特征，但许多特征的排列重要性较低，这说明 LLM 生成的数据可能由少数属性主导而无法充分利用丰富特征范围。
* 可解释性：尽管提到了“可解释性”的好处，但这项工作并没有通过示例、事后模型分析或特征归因系统地评估或说明可解释性，无论是在合成数据上训练的 ML 预测变量，还是合成本身。雷达图和定量表不能替代模型级可解释性。
* 小问题：还有一些令人困惑的符号选择（例如，为什么 $\mathcal{F}^*$ 有时是三个特征，有时是四个特征），缺少对环境特征和个体特定特征之间特征相互作用的讨论，以及跨组合成数据缩放的描述中的细微不一致。

对图/表的引用：

表1、表3（以及表2、\表4中的相应消融）支持了优越下游性能的说法，但很少讨论性能提升的实际意义。
图 2 可视化了不同数据筛选比例对性能的影响，但没有进一步探索筛选比例和数据多样性权衡。
图 3（附录）通过显示双峰置信度和不确定性预过滤来支持管理的需求，但未显示数据筛选后的分布。
图 4 提供了说明性的多阶段提示，但不包括边缘和故障情况。



* 人物画像分组的设定主观：手动创建的年龄段特征，和从前10个最重要特征随机选择3个特征，建议对数字3和最终特征是否对模型性能产生较大影响进一步讨论，敏感性分析，是否有最优的特征集
* 可拓展性：实验在约3000条数据上进行，现实中数据量是百万甚至千万级别，当数据规模和特征维度急剧增加时，特征重要性计算、人物画像分组以及数据筛选过程的计算效率如何
* 成本：调用LLM API进行大规模数据生成和决策模拟的成本很高，实用性较低
* 创新性：其本质上是对LLM进行蒸馏，创新性不够强
* 现实部署：需简要讨论潜在的部署挑战
* 数据筛选机制：基于原始数据训练的筛选模型可能会保留与原始数据分布极为相似的样本，过滤合理但新颖的样本，限制数据多样性，可以引入探索性机制【*探索性机制具体是什么？*】
* 将司机ID作为特征纳入下游模型训练与评估，同时未声明训练/测试是否按司机划分，若同一司机同时出现在训练与测试中，则模型可能借由ID或与ID相关的特征记忆个体接受倾向【*什么意思啊？*】
* 控制变量：没有对GAN、扩散等对比方法进行同强度的事后筛选，建议补充统一过滤器后的横线对比



* 现有研究仅在 SP 调查数据上进行验证，能否验证 LLM-OAP 在真实订单数据上的有效性？或者至少讨论在 SP 与揭示偏好数据 （PR） 上训练时普遍的预期差异？
* 该框架如何确保 XGBoost 过滤器（在 SP 数据上训练）的数据筛选产生真实行为有效性的合成样本，而不是简单地强化原始数据集的非本质特征？是否对合成记录进行了任何人工或领域专家审查？
* 人物画像特征选择使用了哪些标准（从前 10 名中随机选择），替代分组的结果是否存在显着差异（例如，k 均值聚类、确定性前 3 名等）？能否对这种设计选择进行系统的敏感性分析？
* 生成的数据中是否存在任何明确的失败案例或 LLM 幻觉、有害的或逻辑不一致的示例，是否需要人为过滤或重新提示？如果是这样，是否可以公开这些失败示例？
* 能否提供数据多样性和覆盖范围的整理后的统计数据，例如，与原始合成输出相比，有多少独特的人物画像、罕见的行为模式或属性组合在数据筛选中幸存下来？
* 所提出的方法在很大程度上取决于 LLM 的选择和提示的设计。作者是否测试了非英语提示或不同的 LLM，如果有，观察到的下游性能或样本合理性的方差是多少？

**overall**

weak reject。该研究具有一定创新性，实验完成的较好，整个框架比较新颖。然而，存在一些缺陷，包括缺乏真实运营数据验证、仅通过 SP 的数据筛选可能存在的反馈偏差、多样性与报告分析不完整以及缺少 LLM 模拟决策行为有效性的理论支持。通过实质性的修订、改进的实证范围和更深入的理论/定量分析，这项工作可能会成为未来接受的有力候选者。


